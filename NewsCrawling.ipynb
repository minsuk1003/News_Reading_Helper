{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "369be9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from datetime import date, timedelta\n",
    "import io\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375af881",
   "metadata": {},
   "source": [
    "## 뉴스 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "29e186dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_date_list(year):\n",
    "    # 시작 날짜와 종료 날짜 설정\n",
    "    start_date = date(year, 1, 1)\n",
    "    if year == 2023:\n",
    "        end_date = date.today()\n",
    "    else:\n",
    "        end_date = date(year, 12, 31)\n",
    "\n",
    "    # 날짜 리스트 초기화\n",
    "    date_list = []\n",
    "\n",
    "    # 시작 날짜부터 종료 날짜까지 반복하면서 날짜를 리스트에 추가\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        date_list.append(date_str)\n",
    "        current_date += timedelta(days=1)\n",
    "        \n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "40f6930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_list = ['032', '005', '020', '021', '081', '022', '023', '025', '028', '469']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fee268b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_date_list(2023)[0][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ba827b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_crawling(year):\n",
    "    headers = {'user-agent' : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"}\n",
    "    f = open('news.csv', 'w', newline='', encoding='utf-8')\n",
    "    wtr = csv.writer(f)\n",
    "    wtr.writerow([\"date\", \"press\", \"title\", \"url\"])\n",
    "    \n",
    "    date_list = make_date_list(year)\n",
    "\n",
    "    for date in tqdm(date_list): # 날짜별 반복\n",
    "        \n",
    "        if date[-2:] == '15':\n",
    "            time.sleep(60)\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "                \n",
    "        for press in press_list: # 신문사별 반복\n",
    "                \n",
    "            url = f'https://media.naver.com/press/{press}/ranking?type=popular&date={date}'\n",
    "            try:\n",
    "                rs = requests.get(url, headers=headers)\n",
    "            except:\n",
    "                print('RETRY-TIME ERROR!')\n",
    "                time.sleep(5)\n",
    "                rs = requests.get(url, headers=headers)\n",
    "            \n",
    "            rs.encoding = 'UTF-8'\n",
    "            soup = BeautifulSoup(rs.text, 'html.parser')\n",
    "            \n",
    "            link_list = []\n",
    "            title_list = []\n",
    "\n",
    "            titles = soup.find_all(\"strong\", \"list_title\")\n",
    "            for title in titles:\n",
    "                title_list.append(title.get_text())\n",
    "            \n",
    "            links = soup.find_all(\"li\", {'class': ['as_thumb', 'as_no_thumb']})\n",
    "            for link in links:\n",
    "                link_list.append(link.find('a')['href'])\n",
    "            \n",
    "            for i in range(20):\n",
    "                try:\n",
    "                    wtr.writerow([date, press, title_list[i], link_list[i]])\n",
    "                except:\n",
    "                    print(date, press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a95e0b94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████▎                   | 241/320 [26:35<06:13,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n",
      "20230830 022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 320/320 [35:51<00:00,  6.72s/it]\n"
     ]
    }
   ],
   "source": [
    "news_crawling(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b00730de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5433872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230101</td>\n",
       "      <td>32</td>\n",
       "      <td>“아내와 함께 떠난 딸…마지막이 될 줄 몰랐다”</td>\n",
       "      <td>https://n.news.naver.com/article/032/000319644...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230101</td>\n",
       "      <td>32</td>\n",
       "      <td>뜸 들이다 끝난 ‘더 글로리’···복수한다며, 남자가 왜 거기서 나와[리뷰]</td>\n",
       "      <td>https://n.news.naver.com/article/032/000319637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230101</td>\n",
       "      <td>32</td>\n",
       "      <td>이것은 발 토시가 아니다…세련미 더해 돌아온 ‘라떼는’ 패션</td>\n",
       "      <td>https://n.news.naver.com/article/032/000319630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230101</td>\n",
       "      <td>32</td>\n",
       "      <td>경찰, ‘방음터널 화재’ 폐기물 운반용 집게 트럭 소유 업체 압수수색</td>\n",
       "      <td>https://n.news.naver.com/article/032/000319636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230101</td>\n",
       "      <td>32</td>\n",
       "      <td>다시 만난 ‘자낳세’…“월급만으로 살 수 없단 생각엔 변함 없어”</td>\n",
       "      <td>https://n.news.naver.com/article/032/000319644...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63975</th>\n",
       "      <td>20231116</td>\n",
       "      <td>469</td>\n",
       "      <td>\"한동훈 탄핵 필요하면 검토\"... '검사 탄핵' 물러서지 않는 민주당</td>\n",
       "      <td>https://n.news.naver.com/article/469/000077058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63976</th>\n",
       "      <td>20231116</td>\n",
       "      <td>469</td>\n",
       "      <td>제2의 손흥민·이강인도 '전국대회 8강' 못 들면 대학 못 간다?</td>\n",
       "      <td>https://n.news.naver.com/article/469/000077038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63977</th>\n",
       "      <td>20231116</td>\n",
       "      <td>469</td>\n",
       "      <td>尹대통령에 '쪽지메모' 전달한 정대철 “검사출신 넘어 폭넓은 인사 등용하라”[정치행간]</td>\n",
       "      <td>https://n.news.naver.com/article/469/000077045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63978</th>\n",
       "      <td>20231116</td>\n",
       "      <td>469</td>\n",
       "      <td>[르포]\"MMORPG 한계 왔다\"...택진이형까지 새 장르·플랫폼으로 위기 탈출 나섰다</td>\n",
       "      <td>https://n.news.naver.com/article/469/000077061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63979</th>\n",
       "      <td>20231116</td>\n",
       "      <td>469</td>\n",
       "      <td>가짜 서류로 보조금 가로챈 '나눔의 집' 전 시설장... 징역 2년 확정</td>\n",
       "      <td>https://n.news.naver.com/article/469/000077061...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63980 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  press                                             title  \\\n",
       "0      20230101     32                        “아내와 함께 떠난 딸…마지막이 될 줄 몰랐다”   \n",
       "1      20230101     32        뜸 들이다 끝난 ‘더 글로리’···복수한다며, 남자가 왜 거기서 나와[리뷰]   \n",
       "2      20230101     32                 이것은 발 토시가 아니다…세련미 더해 돌아온 ‘라떼는’ 패션   \n",
       "3      20230101     32            경찰, ‘방음터널 화재’ 폐기물 운반용 집게 트럭 소유 업체 압수수색   \n",
       "4      20230101     32              다시 만난 ‘자낳세’…“월급만으로 살 수 없단 생각엔 변함 없어”   \n",
       "...         ...    ...                                               ...   \n",
       "63975  20231116    469           \"한동훈 탄핵 필요하면 검토\"... '검사 탄핵' 물러서지 않는 민주당   \n",
       "63976  20231116    469              제2의 손흥민·이강인도 '전국대회 8강' 못 들면 대학 못 간다?   \n",
       "63977  20231116    469  尹대통령에 '쪽지메모' 전달한 정대철 “검사출신 넘어 폭넓은 인사 등용하라”[정치행간]   \n",
       "63978  20231116    469  [르포]\"MMORPG 한계 왔다\"...택진이형까지 새 장르·플랫폼으로 위기 탈출 나섰다   \n",
       "63979  20231116    469          가짜 서류로 보조금 가로챈 '나눔의 집' 전 시설장... 징역 2년 확정   \n",
       "\n",
       "                                                     url  \n",
       "0      https://n.news.naver.com/article/032/000319644...  \n",
       "1      https://n.news.naver.com/article/032/000319637...  \n",
       "2      https://n.news.naver.com/article/032/000319630...  \n",
       "3      https://n.news.naver.com/article/032/000319636...  \n",
       "4      https://n.news.naver.com/article/032/000319644...  \n",
       "...                                                  ...  \n",
       "63975  https://n.news.naver.com/article/469/000077058...  \n",
       "63976  https://n.news.naver.com/article/469/000077038...  \n",
       "63977  https://n.news.naver.com/article/469/000077045...  \n",
       "63978  https://n.news.naver.com/article/469/000077061...  \n",
       "63979  https://n.news.naver.com/article/469/000077061...  \n",
       "\n",
       "[63980 rows x 4 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "be0c8761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://n.news.naver.com/article/032/0003196443?ntype=RANKING'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['url'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "30fd8427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3200 % (len(df['url']) // 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "78f24fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_content_crawling(data):\n",
    "    headers = {'user-agent' : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"}\n",
    "    f = open('news_content.csv', 'w', newline='', encoding='utf-8')\n",
    "    wtr = csv.writer(f)\n",
    "    wtr.writerow([\"title\", \"content\"])\n",
    "    \n",
    "    for i in range(len(data[\"url\"])):\n",
    "        if i % (len(data['url']) // 20) == 100:\n",
    "            time.sleep(60)\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "        \n",
    "        url = data['url'][i]\n",
    "        try:\n",
    "            rs = requests.get(url, headers=headers)\n",
    "        except:\n",
    "            print('RETRY-TIME ERROR!')\n",
    "            time.sleep(5)\n",
    "            rs = requests.get(url, headers=headers)\n",
    "            \n",
    "        if rs.status_code != 200:\n",
    "            print('CONTENT REQUEST FAILED! : ', url)\n",
    "            return \"REQUEST_ERROR\"\n",
    "        \n",
    "        rs.encoding = 'UTF-8' # html의 인코딩 방식 확인하기\n",
    "        soup = BeautifulSoup(rs.text, 'html.parser')\n",
    "        \n",
    "        title = soup.select_one('#title_area > span').get_text()\n",
    "        print(title)\n",
    "        raw_txt = soup.select_one('#newsct_article')\n",
    "        if raw_txt != None:\n",
    "            for i in raw_txt.find_all('span'):\n",
    "                i.decompose()\n",
    "            raw_txt = raw_txt.get_text(separator='\\n')\n",
    "            #e-mail/기자 제거\n",
    "            pt = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n",
    "            raw_txt = re.sub(pattern=pt, repl='', string=raw_txt)\n",
    "            raw_txt = raw_txt.replace('기자', '')\n",
    "            raw_txt = raw_txt.strip()\n",
    "        \n",
    "            wtr.writerow([title, raw_txt])\n",
    "        else:\n",
    "            \n",
    "            return \"CONTENT_CRAWL_ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "068cced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“아내와 함께 떠난 딸…마지막이 될 줄 몰랐다”\n",
      "뜸 들이다 끝난 ‘더 글로리’···복수한다며, 남자가 왜 거기서 나와[리뷰]\n",
      "CONTENT REQUEST FAILED! :  https://n.news.naver.com/article/032/0003196308?ntype=RANKING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'REQUEST_ERROR'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_content_crawling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b34a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_crawl(u):\n",
    "    headers = {'user-agent' : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"}\n",
    "    try:\n",
    "        rs = requests.get(u, headers=headers)\n",
    "    except:\n",
    "        print('RETRY-TIME ERROR!')\n",
    "        time.sleep(3)\n",
    "        rs = requests.get(u, headers=headers)\n",
    "    if rs.status_code != 200:\n",
    "        print('CONTENT REQUEST FAILED! : ', u)\n",
    "        return \"REQUEST_ERROR\"\n",
    "    rs.encoding = 'UTF-8' # html의 인코딩 방식 확인하기\n",
    "    soup = BeautifulSoup(rs.text, 'html.parser')\n",
    "    raw_txt = soup.select_one('#newsct_article')\n",
    "    if raw_txt != None:\n",
    "        for i in raw_txt.find_all('span'):\n",
    "            i.decompose()\n",
    "        raw_txt = raw_txt.text\n",
    "        #e-mail/기자 제거\n",
    "        pt = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n",
    "        raw_txt = re.sub(pattern=pt, repl='', string=raw_txt)\n",
    "        raw_txt = raw_txt.replace('기자', '')\n",
    "        raw_txt = raw_txt.strip()\n",
    "        return raw_txt\n",
    "    else:\n",
    "        return \"CONTENT_CRAWL_ERROR\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
